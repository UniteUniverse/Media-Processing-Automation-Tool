├── app.py                 # Main Flask application
├── config.py             # Configuration settings
├── requirements.txt      # Dependencies
├── lib/
│   ├── __init__.py
│   ├── folder_monitor.py
│   ├── audio_processor.py
│   ├── diarization.py
│   ├── transcription.py
│   ├── scene_detection.py
│   └── summary_generator.py
│   └── file_registry.py
├── static/
│   ├── css/
│   └── js/
├── templates/
│   ├── base.html
│   ├── dashboard.html
│   └── results.html

1. app.py
#!/usr/bin/env python3
import os
import time
from flask import Flask, render_template, request, jsonify
from werkzeug.utils import secure_filename
from threading import Thread
from dotenv import load_dotenv

from lib.folder_monitor import FolderMonitor
from lib.audio_processor import AudioProcessor
from lib.transcription import TranscriptionService
from lib.diarization import DiarizationService
from lib.scene_detection import SceneDetector
from lib.summary_generator import SummaryGenerator
from lib.file_registry import FileRegistry
from config import Config

load_dotenv()

def wait_for_file_complete(path, stable_secs=3, timeout=120):
    stable_count = 0
    last_size = -1
    for _ in range(timeout):
        try:
            cur_size = os.path.getsize(path)
            if cur_size == last_size:
                stable_count += 1
                if stable_count >= stable_secs:
                    return True
            else:
                stable_count = 0
                last_size = cur_size
        except OSError:
            pass
        time.sleep(1)
    return False

app = Flask(__name__)
app.config.from_object(Config)

# Ensure all output directories exist
for dir_path in [
    app.config["WATCH_FOLDER"],
    app.config["AUDIO_OUTPUT_DIR"],
    app.config["SCENE_OUTPUT_DIR"],
    app.config["SUMMARY_OUTPUT_DIR"],
]:
    os.makedirs(dir_path, exist_ok=True)

audio_processor = AudioProcessor(
    sample_rate=app.config["AUDIO_SAMPLE_RATE"],
    channels=app.config["AUDIO_CHANNELS"],
    audio_output_dir=app.config["AUDIO_OUTPUT_DIR"] # Pass the output directory
)
transcriber = TranscriptionService(api_key=app.config["OPENAI_API_KEY"])
diarizer = DiarizationService(auth_token=app.config["HUGGINGFACE_TOKEN"])
scene_detector = SceneDetector()
summarizer = SummaryGenerator(api_key=app.config["OPENAI_API_KEY"])
file_registry = FileRegistry()

class MediaProcessor:
    def __init__(self):
        self.results = []
        self.processing_status = {}

    def run(self, file_path: str) -> None:
        job_id = os.path.basename(file_path)
        # --- Duplicate check ---
        if file_registry.is_already_processed(file_path):
            self.results.append({
                "file": file_path,
                "status": "duplicate",
                "message": "Already processed, skipping."
            })
            return

        self.processing_status[job_id] = {
            'status': 'processing',
            'stage': 'starting',
            'progress': 0,
            'file': file_path
        }
        
        # Register file as processing
        file_registry.register_file(file_path, status='processing')
        
        try:
            record = self._process_file(file_path)
            self.results.append(record)
            self.processing_status[job_id]['status'] = 'completed'
            self.processing_status[job_id]['progress'] = 100
            
            # Update to completed with result path
            result_path = record.get('summary_file', '')
            file_registry.update_file_status(
                file_registry.calculate_file_hash(file_path), 
                'completed', 
                result_path
            )
            
        except Exception as exc:
            self.processing_status[job_id]['status'] = 'error'
            self.processing_status[job_id]['error'] = str(exc)
            self.results.append({
                "file": file_path,
                "status": "error",
                "message": str(exc),
            })
            
            # Update to error status
            file_registry.update_file_status(
                file_registry.calculate_file_hash(file_path), 
                'error'
            )

    def _process_file(self, file_path: str) -> dict:
        job_id = os.path.basename(file_path)
        self.processing_status[job_id]['stage'] = 'extracting_audio'
        self.processing_status[job_id]['progress'] = 20

        if AudioProcessor.is_video(file_path):
            audio_wav = audio_processor.extract_audio(file_path)
            scenes, keyframes = scene_detector.detect_and_extract(
                video_path=file_path, output_dir=app.config["SCENE_OUTPUT_DIR"]
            )
        else:
            audio_wav = audio_processor.standardize_audio(file_path)
            scenes, keyframes = [], []

        self.processing_status[job_id]['stage'] = 'transcribing'
        self.processing_status[job_id]['progress'] = 40

        transcript_result = transcriber.transcribe(
            audio_wav, language=app.config["LANGUAGE"]
        )
        transcript_text = transcript_result["text"]
        self.processing_status[job_id]['stage'] = 'diarization'
        self.processing_status[job_id]['progress'] = 60

        diarization_rttm = diarizer.diarize(
            audio_wav,
            num_speakers=app.config["NUM_SPEAKERS"],
            output_dir=app.config["AUDIO_OUTPUT_DIR"],
        )

        self.processing_status[job_id]['stage'] = 'generating_summary'
        self.processing_status[job_id]['progress'] = 80

        summary_text = summarizer.generate(
            transcript=transcript_text, images=keyframes
        )

        summary_file = self._save_summary(file_path, summary_text)

        return {
            "file": file_path,
            "audio": audio_wav,
            "diarization": diarization_rttm,
            "scenes": scenes,
            "images": keyframes,
            "transcript": transcript_result,
            "summary_file": summary_file,
            "status": "completed",
        }

    def _save_summary(self, original_file: str, summary: str) -> str:
        base = os.path.basename(original_file)
        stem, _ = os.path.splitext(base)
        out_path = os.path.join(
            app.config["SUMMARY_OUTPUT_DIR"], f"{stem}_summary.txt"
        )
        with open(out_path, "w", encoding="utf-8") as fp:
            fp.write(summary)
        return out_path

processor = MediaProcessor()

# Global monitor instance (but not started)
folder_monitor = None
monitoring_active = False

def start_folder_monitoring(watch_path: str):
    """Start monitoring a specific folder."""
    global folder_monitor, monitoring_active
    
    if monitoring_active:
        stop_folder_monitoring()
    
    folder_monitor = FolderMonitor(
        watch_path=watch_path,
        callback=processor.run,
        supported_ext=Config.SUPPORTED_AUDIO + Config.SUPPORTED_VIDEO,
    )
    folder_monitor.start_async()
    monitoring_active = True
    return True

def stop_folder_monitoring():
    """Stop current folder monitoring."""
    global folder_monitor, monitoring_active
    
    if folder_monitor and monitoring_active:
        folder_monitor._observer.stop()
        folder_monitor._observer.join()
        monitoring_active = False
    return True


@app.route("/", methods=["GET"])
def dashboard():
    return render_template("dashboard.html", results=processor.results)

@app.route("/api/start", methods=["POST"])
def api_start():
    data = request.get_json(force=True)
    watch_dir = data.get("folder", "")
    if not watch_dir or not os.path.isdir(watch_dir):
        return jsonify({"error": "Invalid folder path"}), 400

    try:
        start_folder_monitoring(watch_dir)
        return jsonify({"message": f"Monitoring started for {watch_dir}"})
    except Exception as e:
        return jsonify({"error": f"Failed to start monitoring: {str(e)}"}), 500


@app.route("/api/upload", methods=["POST"])
def api_upload():
    if "file" not in request.files:
        return jsonify({"error": "No file field"}), 400
    
    file = request.files["file"]
    filename = secure_filename(file.filename)
    
    # Use separate upload directory
    dest_dir = Config.UPLOAD_FOLDER  # Changed from WATCH_FOLDER
    os.makedirs(dest_dir, exist_ok=True)
    dest = os.path.join(dest_dir, filename)
    file.save(dest)

    # Check for duplicates
    if file_registry.is_already_processed(dest):
        os.remove(dest)
        return jsonify({"message": "File already processed, skipping."}), 200

    def bg_process():
        if wait_for_file_complete(dest):
            processor.run(dest)
        else:
            print(f"File {dest} did not stabilize in time.")

    Thread(target=bg_process, daemon=True).start()
    return jsonify({"message": f"Uploaded {filename}. Processing will begin shortly."}), 201


@app.route("/api/status", methods=["GET"])
def api_status():
    return jsonify({
        'processing': processor.processing_status,
        'results': processor.results
    })

@app.route("/api/status/<job_id>", methods=["GET"])
def api_job_status(job_id: str):
    if job_id in processor.processing_status:
        return jsonify(processor.processing_status[job_id])
    return jsonify({"error": "Job not found"}), 404

@app.route("/api/results/<int:item_id>", methods=["GET"])
def api_results(item_id: int):
    if 0 <= item_id < len(processor.results):
        return jsonify(processor.results[item_id])
    return jsonify({"error": "Not found"}), 404

@app.route("/api/stop", methods=["POST"])
def api_stop():
    try:
        stop_folder_monitoring()
        return jsonify({"message": "Monitoring stopped"})
    except Exception as e:
        return jsonify({"error": f"Failed to stop monitoring: {str(e)}"}), 500


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True)



2. config.py
"""Shared settings for the Flask application."""
import os
from pathlib import Path
from dotenv import load_dotenv
load_dotenv()

class Config:  # pylint: disable=too-few-public-methods
    # -------------------------------------------------------------------------
    # API Keys
    # -------------------------------------------------------------------------
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "YOUR_OPENAI_KEY")
    HUGGINGFACE_TOKEN = os.getenv("HUGGINGFACE_TOKEN", "YOUR_HF_TOKEN")

    # -------------------------------------------------------------------------
    # Feature Settings
    # -------------------------------------------------------------------------
    LANGUAGE = os.getenv("LANGUAGE", "auto")  # en, ta, hi, or auto
    NUM_SPEAKERS = int(os.getenv("NUM_SPEAKERS", "0")) or None

    # -------------------------------------------------------------------------
    # Directories
    # -------------------------------------------------------------------------
    ROOT_DIR = Path(__file__).parent
    WATCH_FOLDER = os.getenv("WATCH_FOLDER", (ROOT_DIR / "input").resolve().as_posix())
    UPLOAD_FOLDER = os.getenv("UPLOAD_FOLDER", (ROOT_DIR / "uploads").resolve().as_posix())
    AUDIO_OUTPUT_DIR = (ROOT_DIR / "processed" / "audio").as_posix()
    SCENE_OUTPUT_DIR = (ROOT_DIR / "processed" / "images").as_posix()
    SUMMARY_OUTPUT_DIR = (ROOT_DIR / "processed" / "summaries").as_posix()

    # -------------------------------------------------------------------------
    # Audio Processing
    # -------------------------------------------------------------------------
    AUDIO_SAMPLE_RATE = 16_000
    AUDIO_CHANNELS = 1

    # -------------------------------------------------------------------------
    # Supported Extensions
    # -------------------------------------------------------------------------
    SUPPORTED_AUDIO = (
        ".mp3",
        ".wav",
        ".flac",
        ".m4a",
        ".aac",
        ".ogg",
        ".wma",
    )
    SUPPORTED_VIDEO = (
        ".mp4",
        ".mov",
        ".mkv",
        ".avi",
        ".webm",
        ".flv",
        ".wmv",
    )

3. requiremnts.txt
# Python 3.11 Compatible Requirements - RECOMMENDED
# Generated for media processing automation tool

# Core Web Framework
Flask==3.1.1
python-dotenv==1.0.1
requests==2.32.3
httpx==0.27.0

# File System Monitoring
watchdog==3.0.0

# AI/ML Libraries
openai==1.51.0
pyannote.audio==3.3.2
pytorch-lightning==2.5.0
torchmetrics==1.4.0

# Audio/Video Processing
opencv-python==4.10.0.82
ffmpeg-python==0.2.0
moviepy==1.0.3
scenedetect[opencv]==0.6.6

# Scientific Computing
numpy==1.26.4
scipy==1.11.4

# Additional Dependencies (install if needed)
# torch>=2.0.0
# torchaudio>=2.0.0
# torchvision>=0.15.0
# transformers>=4.30.0
# librosa>=0.10.0
# soundfile>=0.12.0
# matplotlib>=3.7.0
# pandas>=2.0.0

4. lib/__init__.py
"""Library namespace for automation_tool."""

5. lib/folder_monitor.py
"""Folder monitor using Watchdog."""
import os
import time
import threading
from pathlib import Path
from typing import Callable, Tuple

from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler, FileCreatedEvent


class _Handler(FileSystemEventHandler):
    """Internal handler capturing newly created files."""

    def __init__(
        self,
        callback: Callable[[str], None],
        supported_ext: Tuple[str, ...],
    ):
        super().__init__()
        self.callback = callback
        self.supported_ext = supported_ext

    # ---------------------------------------------------------------------
    def on_created(self, event: FileCreatedEvent) -> None:
        if event.is_directory:
            return
        file_path = event.src_path
        if file_path.lower().endswith(self.supported_ext):
            if _wait_for_completion(file_path):
                self.callback(file_path)


def _wait_for_completion(path: str, stable_secs: int = 3, timeout: int = 120) -> bool:
    """Poll file size until unchanged for `stable_secs` seconds."""
    stable_count = 0
    last_size = -1
    for _ in range(timeout):
        try:
            cur_size = os.path.getsize(path)
            if cur_size == last_size:
                stable_count += 1
                if stable_count >= stable_secs:
                    return True
            else:
                stable_count = 0
                last_size = cur_size
        except OSError:
            pass
        time.sleep(1)
    return False


class FolderMonitor:
    """Public wrapper that manages Watchdog observer threads."""

    def __init__(
        self,
        watch_path: str,
        callback: Callable[[str], None],
        supported_ext: Tuple[str, ...],
    ):
        self.watch_path = watch_path
        self.callback = callback
        self.supported_ext = supported_ext
        self._observer = Observer()
        self._observer.schedule(
            _Handler(callback, supported_ext), watch_path, recursive=False
        )

    # ---------------------------------------------------------------------
    def start_async(self) -> None:
        thread = threading.Thread(target=self._observer.start, daemon=True)
        thread.start()

6. lib/audio_processor.py
"""Audio extraction and normalization."""
import subprocess
import os
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO)

class AudioProcessor:
    """Handles audio tasks."""

    video_ext = (
        ".mp4",
        ".mov",
        ".mkv",
        ".avi",
        ".webm",
        ".flv",
        ".wmv",
    )

    def __init__(self, sample_rate: int = 16_000, channels: int = 1, audio_output_dir: str = None):
        self.sample_rate = sample_rate
        self.channels = channels
        self.audio_output_dir = audio_output_dir # Store the output directory

        if self.audio_output_dir:
            os.makedirs(self.audio_output_dir, exist_ok=True) # Ensure output dir exists

    # ------------------------------------------------------------------
    @staticmethod
    def is_video(path: str) -> bool:
        return path.lower().endswith(AudioProcessor.video_ext)

    # ------------------------------------------------------------------
    def extract_audio(self, video_path: str) -> str:
        """Return path to extracted WAV from video, saved to audio_output_dir."""
        stem = Path(video_path).stem # Get stem without suffix
        if not self.audio_output_dir:
            logging.warning("Audio output directory not set for AudioProcessor. Using video_path's directory.")
            out_path = Path(video_path).with_suffix(".wav").as_posix()
        else:
            out_path = Path(self.audio_output_dir) / f"{stem}.wav" # Save to dedicated output dir

        cmd = [
            "ffmpeg", "-y", "-i", video_path, "-vn",
            "-acodec", "pcm_s16le", "-ar", str(self.sample_rate),
            "-ac", str(self.channels), out_path.as_posix(),
        ]
        logging.info(f"FFmpeg command for extraction: {' '.join(cmd)}")
        try:
            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE) # Capture stderr for debugging
        except subprocess.CalledProcessError as e:
            logging.error(f"FFmpeg error: {e.stderr.decode()}")
            raise
        return out_path.as_posix()

    # ------------------------------------------------------------------
    def standardize_audio(self, audio_path: str) -> str:
        """Convert arbitrary audio to 16 kHz mono WAV, saved to audio_output_dir."""
        stem = Path(audio_path).stem
        if not self.audio_output_dir:
            logging.warning("Audio output directory not set for AudioProcessor. Using audio_path's directory.")
            out_path = Path(audio_path).with_suffix("_std.wav").as_posix()
        else:
            out_path = Path(self.audio_output_dir) / f"{stem}_std.wav" # Save to dedicated output dir

        cmd = [
            "ffmpeg", "-y", "-i", audio_path,
            "-acodec", "pcm_s16le", "-ar", str(self.sample_rate),
            "-ac", str(self.channels), out_path.as_posix(),
        ]
        logging.info(f"FFmpeg command for standardization: {' '.join(cmd)}")
        try:
            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)
        except subprocess.CalledProcessError as e:
            logging.error(f"FFmpeg error: {e.stderr.decode()}")
            raise
        return out_path.as_posix()

7. lib/diarization.py
"""Speaker diarization with pyannote.audio."""
from pathlib import Path
from typing import Optional
from pyannote.audio import Pipeline


class DiarizationService:
    """Encapsulates Hugging Face diarization pipeline."""

    def __init__(self, auth_token: str):
        self.pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization-3.1", use_auth_token=auth_token
        )

    # ------------------------------------------------------------------
    def diarize(
        self,
        wav_path: str,
        num_speakers: Optional[int],
        output_dir: str,
    ) -> str:
        diarization = (
            self.pipeline(wav_path, num_speakers=num_speakers)
            if num_speakers
            else self.pipeline(wav_path)
        )
        out_file = Path(output_dir) / (Path(wav_path).stem + ".rttm")
        with open(out_file, "w", encoding="utf-8") as fp:
            diarization.write_rttm(fp)
        return out_file.as_posix()



8. lib/transcription.py
"""OpenAI Whisper transcription service."""
from pathlib import Path
from typing import Dict, Any
from openai import OpenAI


class TranscriptionService:
    """Handles calls to OpenAI's speech-to-text."""

    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)

    def transcribe(self, audio_path: str, language: str = "auto") -> Dict[str, Any]:
        """Transcribe audio and return a dictionary-like structure."""
        with open(audio_path, "rb") as fp:
            resp = self.client.audio.transcriptions.create(
                model="whisper-1",
                file=fp,
                response_format="verbose_json",
                timestamp_granularities=["word"],
                language=None if language == "auto" else language,
            )
        
        # Convert the response to a proper dictionary
        if hasattr(resp, 'model_dump'):
            # For Pydantic v2
            transcript_dict = resp.model_dump()
        elif hasattr(resp, 'dict'):
            # For Pydantic v1
            transcript_dict = resp.dict()
        else:
            # Fallback manual conversion
            transcript_dict = {
                "text": resp.text,
                "language": getattr(resp, 'language', 'unknown'),
                "duration": getattr(resp, 'duration', 0),
                "segments": getattr(resp, 'segments', []),
                "words": getattr(resp, 'words', [])
            }
        
        # Persist JSON next to audio
        json_path = Path(audio_path).with_suffix(".json")
        json_path.write_text(str(transcript_dict), encoding="utf-8")
        
        return transcript_dict


9.lib/scene_detection.py
"""Scene change detection and key-frame extraction."""
import os
from typing import List, Tuple
import cv2
from scenedetect import detect, AdaptiveDetector


class SceneDetector:
    """High-level scene change utility."""

    def detect_and_extract(
        self, video_path: str, output_dir: str
    ) -> Tuple[List[Tuple[str, str]], List[str]]:
        """Return (scene timecodes, keyframe image paths)."""
        scenes = detect(video_path, AdaptiveDetector())
        keyframes = []
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)

        for idx, (start, end) in enumerate(scenes):
            mid_time = (start.get_seconds() + end.get_seconds()) / 2
            cap.set(cv2.CAP_PROP_POS_FRAMES, int(mid_time * fps))
            ret, frame = cap.read()
            if not ret:
                continue
            img_path = os.path.join(output_dir, f"{os.path.basename(video_path)}_scene_{idx:03d}.jpg")
            cv2.imwrite(img_path, frame)
            keyframes.append(img_path)

        cap.release()
        return [(s[0].get_timecode(), s[1].get_timecode()) for s in scenes], keyframes


10.lib/summary_generator.py
"""Generate concise, actionable meeting summaries."""
import base64
from typing import List
from openai import OpenAI
import os

class SummaryGenerator:
    """Uses GPT-4 to draft a structured summary."""

    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)

    # ------------------------------------------------------------------
    def generate(self, transcript: str, images: List[str]) -> str:
        prompt = self._build_prompt(transcript, images)
        resp = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You are an expert note-taker. Create structured, bullet-point "
                        "summaries with action items and decisions."
                    ),
                },
                {"role": "user", "content": prompt},
            ],
            temperature=0.4,
        )
        return resp.choices[0].message.content.strip()

    # ------------------------------------------------------------------
    @staticmethod
    def _build_prompt(transcript: str, images: List[str]) -> str:
        image_txt = "\n".join(f"- {os.path.basename(img)}" for img in images) or "No images."
        return (
            f"Transcript:\n{transcript}\n\n"
            f"Scene Images:\n{image_txt}\n\n"
            "Please produce:\n"
            "• Executive summary\n"
            "• Action items (with owners if identifiable)\n"
            "• Key instructions or decisions"
        )

11.lib/file_registry.py
import os
import sqlite3
import hashlib
from pathlib import Path
from typing import Optional, Dict, List
from datetime import datetime

class FileRegistry:
    """Manages a database of processed files to prevent duplicates."""
    
    def __init__(self, db_path: str = "processed_files.db"):
        self.db_path = db_path
        self._init_database()
    
    def _init_database(self):
        """Initialize the SQLite database for file tracking."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS processed_files (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                file_hash TEXT UNIQUE NOT NULL,
                file_path TEXT NOT NULL,
                file_size INTEGER NOT NULL,
                original_name TEXT NOT NULL,
                processed_at TIMESTAMP NOT NULL,
                status TEXT NOT NULL,
                result_path TEXT
            )
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_file_hash ON processed_files(file_hash)
        ''')
        
        conn.commit()
        conn.close()
    
    def calculate_file_hash(self, file_path: str) -> str:
        """Calculate SHA-256 hash of file content."""
        hash_sha256 = hashlib.sha256()
        
        try:
            with open(file_path, "rb") as f:
                # Read file in chunks to handle large files efficiently
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_sha256.update(chunk)
            return hash_sha256.hexdigest()
        except Exception as e:
            raise Exception(f"Error calculating hash for {file_path}: {e}")
    
    def is_already_processed(self, file_path: str) -> Optional[Dict]:
        """Check if file has already been processed based on content hash."""
        file_hash = self.calculate_file_hash(file_path)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT * FROM processed_files 
            WHERE file_hash = ? AND status = 'completed'
        ''', (file_hash,))
        
        result = cursor.fetchone()
        conn.close()
        
        if result:
            return {
                'id': result[0],
                'file_hash': result[1],
                'file_path': result[2],
                'file_size': result[3],
                'original_name': result[4],
                'processed_at': result[5],
                'status': result[6],
                'result_path': result[7]
            }
        return None
    
    def register_file(self, file_path: str, status: str = 'processing', result_path: str = None):
        """Register a file in the database."""
        file_hash = self.calculate_file_hash(file_path)
        file_size = os.path.getsize(file_path)
        original_name = os.path.basename(file_path)
        processed_at = datetime.now().isoformat()
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR REPLACE INTO processed_files 
            (file_hash, file_path, file_size, original_name, processed_at, status, result_path)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (file_hash, file_path, file_size, original_name, processed_at, status, result_path))
        
        conn.commit()
        conn.close()
        
        return file_hash
    
    def update_file_status(self, file_hash: str, status: str, result_path: str = None):
        """Update the status of a processed file."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            UPDATE processed_files 
            SET status = ?, result_path = ?
            WHERE file_hash = ?
        ''', (status, result_path, file_hash))
        
        conn.commit()
        conn.close()
    
    def get_processed_files(self) -> List[Dict]:
        """Get all processed files."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT * FROM processed_files ORDER BY processed_at DESC')
        results = cursor.fetchall()
        conn.close()
        
        return [
            {
                'id': row[0],
                'file_hash': row[1],
                'file_path': row[2],
                'file_size': row[3],
                'original_name': row[4],
                'processed_at': row[5],
                'status': row[6],
                'result_path': row[7]
            }
            for row in results
        ]
    
    def cleanup_orphaned_records(self):
        """Remove records for files that no longer exist."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT file_hash, file_path FROM processed_files')
        records = cursor.fetchall()
        
        for file_hash, file_path in records:
            if not os.path.exists(file_path):
                cursor.execute('DELETE FROM processed_files WHERE file_hash = ?', (file_hash,))
        
        conn.commit()
        conn.close()


12. static/css/main.css
body {
  padding-bottom: 4rem;
}

table td {
  vertical-align: middle;
}

13. static/js/dashboard.js
document.addEventListener("DOMContentLoaded", () => {
  const startBtn = document.getElementById("start-btn");
  const folderInput = document.getElementById("folder-path");
  const uploadForm = document.getElementById("upload-form");
  const resultsTable = document.getElementById("results-table");
  
  let pollInterval;
  let isPolling = false;
  
  // Start polling for status updates
  function startPolling() {
    if (isPolling) return;
    isPolling = true;
    
    pollInterval = setInterval(async () => {
      try {
        const response = await fetch('/api/status');
        const data = await response.json();
        updateResultsTable(data.results, data.processing);
      } catch (error) {
        console.error('Error polling status:', error);
      }
    }, 2000); // Poll every 2 seconds
  }
  
  // Update results table dynamically
  function updateResultsTable(results, processing) {
    const tbody = resultsTable.querySelector('tbody');
    tbody.innerHTML = '';
    
    // Add completed results
    results.forEach((item, index) => {
      const row = createResultRow(index, item, null);
      tbody.appendChild(row);
    });
    
    // Add processing jobs
    Object.entries(processing).forEach(([jobId, status]) => {
      const row = createResultRow('...', { file: status.file || jobId }, status);
      tbody.appendChild(row);
    });
  }
  
  // Create table row with progress indicator
  function createResultRow(index, item, processingStatus) {
    const row = document.createElement('tr');
    
    if (processingStatus) {
      // Processing row with progress bar
      row.innerHTML = `
        <td>${index}</td>
        <td>${item.file}</td>
        <td>
          <div class="progress mb-1">
            <div class="progress-bar progress-bar-striped progress-bar-animated" 
                 role="progressbar" 
                 style="width: ${processingStatus.progress}%">
              ${processingStatus.progress}%
            </div>
          </div>
          <small class="text-muted">${processingStatus.stage}</small>
        </td>
        <td>—</td>
      `;
    } else {
      // Completed row
      const summaryLink = item.status === 'completed' ? 
        `<a href="/static/${item.summary_file.split('static/')[1]}" 
           class="btn btn-sm btn-success">Download</a>` : '—';
      
      row.innerHTML = `
        <td>${index}</td>
        <td>${item.file}</td>
        <td><span class="badge bg-success">${item.status}</span></td>
        <td>${summaryLink}</td>
      `;
    }
    
    return row;
  }
  
  // Enhanced upload handler with progress feedback
  uploadForm.addEventListener("submit", async (e) => {
    e.preventDefault();
    
    const submitBtn = uploadForm.querySelector('button[type="submit"]');
    const originalText = submitBtn.textContent;
    
    // Show loading state
    submitBtn.disabled = true;
    submitBtn.innerHTML = '<span class="spinner-border spinner-border-sm" role="status"></span> Uploading...';
    
    try {
      const formData = new FormData(uploadForm);
      const res = await fetch("/api/upload", {
        method: "POST",
        body: formData,
      });
      
      const data = await res.json();
      
      if (res.ok) {
        startPolling();
        showNotification(data.message, 'success');
        uploadForm.reset();
      } else {
        showNotification(data.error, 'error');
      }
    } catch (error) {
      showNotification('Upload failed: ' + error.message, 'error');
    } finally {
      submitBtn.disabled = false;
      submitBtn.textContent = originalText;
    }
  });
  
  // Enhanced start monitoring handler
  startBtn.addEventListener("click", async () => {
    const folder = folderInput.value.trim();
    if (!folder) {
      showNotification("Enter a valid path.", 'error');
      return;
    }
    
    startBtn.disabled = true;
    startBtn.textContent = 'Starting...';
    
    try {
      const res = await fetch("/api/start", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ folder }),
      });
      
      const data = await res.json();
      
      if (res.ok) {
        startPolling();
        showNotification(data.message, 'success');
        startBtn.textContent = 'Monitoring Active';
        startBtn.className = 'btn btn-success';
      } else {
        showNotification(data.error, 'error');
        startBtn.disabled = false;
        startBtn.textContent = 'Start Monitoring';
      }
    } catch (error) {
      showNotification('Failed to start monitoring: ' + error.message, 'error');
      startBtn.disabled = false;
      startBtn.textContent = 'Start Monitoring';
    }
  });
  
  // Notification system
  function showNotification(message, type) {
    const alertClass = type === 'success' ? 'alert-success' : 'alert-danger';
    const alertDiv = document.createElement('div');
    alertDiv.className = `alert ${alertClass} alert-dismissible fade show`;
    alertDiv.innerHTML = `
      ${message}
      <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
    `;
    
    document.querySelector('.container').insertBefore(alertDiv, document.querySelector('h2'));
    
    setTimeout(() => {
      if (alertDiv.parentNode) {
        alertDiv.remove();
      }
    }, 5000);
  }
  function updateMonitoringStatus(isActive, folder = '') {
    const startBtn = document.getElementById('start-btn');
    const stopBtn = document.getElementById('stop-btn'); // Add stop button
    
    if (isActive) {
        startBtn.textContent = `Monitoring: ${folder}`;
        startBtn.className = 'btn btn-success';
        startBtn.disabled = true;
        stopBtn.disabled = false;
    } else {
        startBtn.textContent = 'Start Monitoring';
        startBtn.className = 'btn btn-outline-primary';
        startBtn.disabled = false;
        stopBtn.disabled = true;
    }
}

  
  // Start polling on page load
  startPolling();
});



14. templates/base.html
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Media Processor</title>
  <link rel="stylesheet" href="{{ url_for('static', filename='css/main.css') }}">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css">
</head>
<body>
  <nav class="navbar bg-dark navbar-dark mb-4">
      <div class="container-fluid">
          <span class="navbar-brand">Media Processing Automation Tool</span>
      </div>
  </nav>
  <main class="container">
      {% block content %}{% endblock %}
  </main>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
  <script src="{{ url_for('static', filename='js/dashboard.js') }}"></script>
</body>
</html>

15. templates/dashboard.html
{% extends "base.html" %}
{% block content %}

<div id="notifications"></div>

<h2>Configuration</h2>
<form id="config-form" class="row g-3 mb-4">
  <div class="col-md-4">
    <label for="language" class="form-label">Language Preference</label>
    <select id="language" class="form-select">
      <option value="auto" selected>Auto-detect</option>
      <option value="en">English</option>
      <option value="ta">Tamil</option>
      <option value="hi">Hindi</option>
    </select>
  </div>
  <div class="col-md-4">
    <label for="speakers" class="form-label">Number of Speakers</label>
    <input type="number" id="speakers" class="form-control" min="1" max="10">
  </div>
</form>

<h2>Folder Monitor</h2>
<div class="row mb-4">
  <div class="col-md-8">
    <input type="text" id="folder-path" class="form-control"
           placeholder="Path to watch (absolute or relative)">
  </div>
  <div class="col-md-4">
    <button class="btn btn-outline-primary w-100" id="start-btn">Start Monitoring</button>
  </div>
</div>

<h2>Manual Upload</h2>
<form id="upload-form" enctype="multipart/form-data" class="mb-4">
  <div class="row">
    <div class="col-md-8">
      <input class="form-control" type="file" name="file" accept="audio/*,video/*" required>
    </div>
    <div class="col-md-4">
      <button type="submit" class="btn btn-primary w-100">Upload File</button>
    </div>
  </div>
</form>

<h2>Processing Results</h2>
<div class="table-responsive">
  <table class="table table-striped" id="results-table">
    <thead>
      <tr>
        <th width="5%">#</th>
        <th width="40%">File</th>
        <th width="30%">Status</th>
        <th width="25%">Summary</th>
      </tr>
    </thead>
    <tbody>
      <!-- Dynamic content will be inserted here -->
    </tbody>
  </table>
</div>

{% endblock %}


16. templates/results.html
{% extends "base.html" %}
{% block content %}
<h2>Detailed Result</h2>
<p>Coming soon…</p>
{% endblock %}
